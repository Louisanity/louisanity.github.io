---
title: "Tensor Network-Based Quantum-Train with Distributed Ansatz for Scalable Quantum-Classical Models"
collection: publications
category: conferences
permalink: /publication/2025-04-06-tensor-network-qt
excerpt: 'A scalable Quantum-Train framework replaces MLPs with tensor networks and introduces a distributed ansatz for large-scale quantum-classical learning.'
date: 2025-04-06
venue: 'ICASSP 2025 – IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'
paperurl: 'https://ieeexplore.ieee.org/document/10889597'
citation: 'Liu, Chen-Yu; Lin, Chu-Hsuan Abraham; &amp; Chen, Kuan-Cheng. (2025). &quot;Tensor Network-Based Quantum-Train with Distributed Ansatz for Scalable Quantum-Classical Models.&quot; <i>Proceedings of ICASSP 2025 – IEEE International Conference on Acoustics, Speech and Signal Processing</i>, 1–4.'
---

This paper enhances the **Quantum-Train (QT)** framework by integrating a **tensor network model** and a **distributed circuit ansatz** for scalable hybrid quantum-classical learning. Key innovations include:

* Replacing the traditional **multi-layer perceptron (MLP)** with a **tensor network**, improving scalability and interpretability.  
* Leveraging **multiple small QPU nodes** to support large-scale quantum machine learning tasks.  
* Maintaining **low parameter complexity** and ensuring **quantum-free inference**, critical for practical deployment.

Experimental benchmarks demonstrate improved performance and compactness, positioning this framework as a robust solution for scalable quantum-classical model training.
